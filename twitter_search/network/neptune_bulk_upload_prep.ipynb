{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import packages\n",
        "\n",
        "import json\n",
        "import os\n",
        "import csv\n",
        "import uuid\n",
        "import sys\n",
        "from datetime import datetime, timezone\n",
        "from zoneinfo import ZoneInfo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## CSV Preparation for Bulk Upload"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "# read in json\n",
        "\n",
        "base_path = \"/Users/vjoseph/Desktop/eel_projects/global-rct/twitter_search/twitter_search/data/networks\"\n",
        "city_name = \"guatemala\"\n",
        "raw_network_path = os.path.join(base_path, city_name, f\"{city_name}.json\")\n",
        "with open(raw_network_path, 'r') as file:\n",
        "    raw_network = json.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "136\n"
          ]
        }
      ],
      "source": [
        "# inspect raw file and subset\n",
        "\n",
        "print(type(raw_network))\n",
        "print(len(raw_network))\n",
        "\n",
        "# sub_network = raw_network[:5]\n",
        "# sub_network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing root user: 1869546683450765312\n",
            "!! Root user does not meet location criteria. Skipping... !!\n",
            "Processing root user: 1845837992637661190\n",
            "Processing root user: 1842313354616168448\n",
            "Processing root user: 1782609390639501313\n",
            "!! Root user does not meet location criteria. Skipping... !!\n",
            "Processing root user: 1752054121937387520\n",
            "Processing root user: 1750902493024821248\n",
            "Processing root user: 1703817165676158976\n",
            "Processing root user: 1593487901349888001\n",
            "Processing root user: 1572777218090098688\n",
            "Processing root user: 1561130432938344453\n",
            "Processing root user: 1560859776745103360\n",
            "Processing root user: 1539976222007930880\n",
            "Processing root user: 1504148226970202121\n",
            "Processing root user: 1469338796990906378\n",
            "Processing root user: 1445089457217150988\n",
            "Processing root user: 1439523648755445763\n",
            "Processing root user: 1433925962249510926\n",
            "Processing root user: 1430913468115275783\n",
            "Processing root user: 1429991394010148874\n",
            "Processing root user: 1371304624339181571\n",
            "Processing root user: 1369869726436954113\n",
            "!! Root user does not meet location criteria. Skipping... !!\n",
            "Processing root user: 1359572058670252033\n",
            "Processing root user: 1291508286353739780\n",
            "Processing root user: 1286005012485767169\n",
            "Processing root user: 14180781\n",
            "Processing root user: 26860664\n",
            "Processing root user: 1265114671322988551\n",
            "Processing root user: 40832712\n",
            "Processing root user: 1253526934144921601\n",
            "Processing root user: 46211678\n",
            "Processing root user: 1244825578995417089\n",
            "Processing root user: 49538114\n",
            "Processing root user: 1241496971678015489\n",
            "Processing root user: 52109461\n",
            "Processing root user: 1234507089483046913\n",
            "Processing root user: 62976722\n",
            "Processing root user: 1205869850981281792\n",
            "Processing root user: 64787241\n",
            "Processing root user: 1179785468264812545\n",
            "Processing root user: 70251539\n",
            "Processing root user: 1133114841420521472\n",
            "Processing root user: 85928468\n",
            "Processing root user: 1130244097749540864\n",
            "Processing root user: 89030065\n",
            "Processing root user: 1059845923424141312\n",
            "Processing root user: 94355727\n",
            "Processing root user: 991722416006156288\n",
            "Processing root user: 102728856\n",
            "Processing root user: 938078809454268416\n",
            "Processing root user: 895022677018255360\n",
            "Processing root user: 105063244\n",
            "Processing root user: 106306650\n",
            "Processing root user: 844261226427375616\n",
            "Processing root user: 817889924565401602\n",
            "Processing root user: 111451574\n",
            "Processing root user: 796325278167531522\n",
            "Processing root user: 144901792\n",
            "Processing root user: 786584404185395200\n",
            "Processing root user: 145059028\n",
            "Processing root user: 160601853\n",
            "Processing root user: 164564091\n",
            "Processing root user: 179379293\n",
            "Processing root user: 185050996\n",
            "Processing root user: 194166983\n",
            "Processing root user: 207874674\n",
            "Processing root user: 226953533\n",
            "Processing root user: 236729387\n",
            "Processing root user: 249711217\n",
            "Processing root user: 266645038\n",
            "Processing root user: 269410195\n",
            "Processing root user: 271035994\n",
            "Processing root user: 281322002\n",
            "Processing root user: 290971226\n",
            "Processing root user: 298361976\n",
            "Processing root user: 308765522\n",
            "Processing root user: 311792996\n",
            "Processing root user: 311848983\n",
            "Processing root user: 774280696856797185\n",
            "Processing root user: 330497248\n",
            "Processing root user: 722884829084160000\n",
            "Processing root user: 339401395\n",
            "Processing root user: 721499688998809600\n",
            "Processing root user: 347463847\n",
            "Processing root user: 714865097139597312\n",
            "Processing root user: 348231010\n",
            "Processing root user: 3771339442\n",
            "Processing root user: 354889845\n",
            "Processing root user: 3295807061\n",
            "Processing root user: 356997634\n",
            "Processing root user: 3226333064\n",
            "Processing root user: 360408595\n",
            "Processing root user: 3186977617\n",
            "Processing root user: 368083685\n",
            "Processing root user: 3163199598\n",
            "Processing root user: 3154050991\n",
            "Processing root user: 372126670\n",
            "Processing root user: 3151408944\n",
            "Processing root user: 388700305\n",
            "Processing root user: 396836455\n",
            "Processing root user: 450859699\n",
            "Processing root user: 3108154005\n",
            "Processing root user: 462229873\n",
            "Processing root user: 3033192066\n",
            "Processing root user: 472056631\n",
            "Processing root user: 2911387365\n",
            "Processing root user: 491689703\n",
            "Processing root user: 2827099094\n",
            "Processing root user: 2803901094\n",
            "Processing root user: 2687943848\n",
            "Processing root user: 494837476\n",
            "Processing root user: 2506342076\n",
            "Processing root user: 502117040\n",
            "Processing root user: 2467942825\n",
            "Processing root user: 509041284\n",
            "Processing root user: 2458699754\n",
            "Processing root user: 526921529\n",
            "Processing root user: 2358851191\n",
            "Processing root user: 577547749\n",
            "Processing root user: 2350014685\n",
            "Processing root user: 586346508\n",
            "Processing root user: 1967411425\n",
            "Processing root user: 1695086714\n",
            "Processing root user: 588775175\n",
            "Processing root user: 1694885089\n",
            "Processing root user: 612845237\n",
            "Processing root user: 901835456\n",
            "Processing root user: 1045159140\n",
            "Processing root user: 1045159140\n",
            "!! Root user has already been processed. Skipping... !!\n",
            "Processing root user: 1228084327\n",
            "Processing root user: 1228084327\n",
            "!! Root user has already been processed. Skipping... !!\n",
            "Processing root user: 1282031748\n",
            "Processing root user: 1282031748\n",
            "!! Root user has already been processed. Skipping... !!\n",
            "Processing root user: 1374698576\n",
            "Processing root user: 1467812144\n",
            "Processing root user: 1581191659\n",
            "Processing root user: 1600081652\n"
          ]
        }
      ],
      "source": [
        "# Creating vertices and edges\n",
        "\n",
        "## helper functions\n",
        "\n",
        "def write_dict_to_csv(file_name, data, fieldnames=None):\n",
        "    # Check if the file already exists\n",
        "    file_exists = os.path.isfile(file_name)\n",
        "\n",
        "    # Set fieldnames\n",
        "    if not fieldnames:\n",
        "        fieldnames=data.keys()\n",
        "    \n",
        "    with open(file_name, mode='a', newline='', encoding='utf-8') as file:\n",
        "        # Create a CSV DictWriter object\n",
        "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
        "        \n",
        "        # Write the header only if the file does not exist or is empty\n",
        "        if not file_exists or os.stat(file_name).st_size == 0:\n",
        "            writer.writeheader()\n",
        "        \n",
        "        # Write the dictionary as a row\n",
        "        writer.writerow(data)\n",
        "\n",
        "def handle_date_attribute(timestamp_str):\n",
        "    naive_dt = datetime.fromisoformat(timestamp_str)\n",
        "    # If the datetime already has timezone info and it's UTC, return as is\n",
        "    if naive_dt.tzinfo is not None and naive_dt.tzinfo == timezone.utc:\n",
        "        return naive_dt.isoformat()\n",
        "    # Otherwise, convert from CST to UTC\n",
        "    cst_dt = naive_dt.replace(tzinfo=ZoneInfo(\"America/Chicago\"))\n",
        "    utc_dt = cst_dt.astimezone(ZoneInfo(\"UTC\"))\n",
        "    return utc_dt.isoformat()\n",
        "\n",
        "def create_user_vertex(user_attributes):\n",
        "    user_vertex = {}\n",
        "    user_vertex['~id'] = str(user_attributes['user_id'])\n",
        "    user_vertex['~label'] = \"User\"\n",
        "\n",
        "    if 'processing_status' in user_attributes:\n",
        "        user_attributes['retweeter_status'] = user_attributes['processing_status']\n",
        "        user_attributes['follower_status'] = user_attributes['processing_status']\n",
        "\n",
        "    if 'last_processed' in user_attributes:\n",
        "        if user_attributes['processing_status'] == \"pending\":\n",
        "            user_attributes['retweeter_last_processed'] = \"null\"\n",
        "            user_attributes['follower_last_processed'] = \"null\"\n",
        "        else:\n",
        "            user_attributes['retweeter_last_processed'] = user_attributes['last_processed']\n",
        "            user_attributes['follower_last_processed'] = user_attributes['last_processed']      \n",
        "\n",
        "    # Define the integer attribute names\n",
        "    int_attributes = {'followers_count', 'following_count', 'tweets_count'}\n",
        "    exclude_attributes = {'user_id', 'tweets', 'followers', 'description', 'processing_status', 'last_processed'}\n",
        "    date_attributes = {'extracted_at', 'retweeter_last_processed', 'follower_last_processed', 'last_updated'}\n",
        "\n",
        "    # Optimized attribute assignment\n",
        "    for attr, value in user_attributes.items():\n",
        "        # Skip excluded attributes\n",
        "        if attr in exclude_attributes:\n",
        "            continue\n",
        "        \n",
        "        # Handle integer attributes\n",
        "        if attr in int_attributes:\n",
        "            # Efficiently handle missing or invalid integer values\n",
        "            user_vertex[f'{attr}:Int'] = -99 if not value else int(value)\n",
        "        # Handle date attributes\n",
        "        elif attr in date_attributes:\n",
        "            user_vertex[attr] = value if value == \"null\" else handle_date_attribute(value) if value else \"null\"\n",
        "        # Handle non-integer attributes\n",
        "        else:\n",
        "            # Assign \"null\" for empty values, otherwise the value itself\n",
        "            user_vertex[attr] = \"null\" if not value else value\n",
        "\n",
        "    if 'tweets' in user_attributes and user_attributes['tweets']:\n",
        "        timestamps = [datetime.fromisoformat(tweet['created_at']) for tweet in user_attributes['tweets']]\n",
        "        most_recent_timestamp = max(timestamps)\n",
        "        user_vertex['last_tweeted_at'] = most_recent_timestamp.isoformat()\n",
        "    else:\n",
        "        user_vertex['last_tweeted_at'] = \"null\"\n",
        "    \n",
        "    return user_vertex\n",
        "\n",
        "def create_city_edge(source, target):\n",
        "    edge = {}\n",
        "    edge['~id'] = str(uuid.uuid4())\n",
        "    edge['~from'] = source\n",
        "    edge['~to'] = target\n",
        "    edge['~label'] = \"BELONGS_TO\"\n",
        "    return edge\n",
        "\n",
        "def create_retweeter_edges(sources, target):\n",
        "    edges = []\n",
        "    for source, attributes in sources.items():\n",
        "        edge = {}\n",
        "        edge['~id'] = str(uuid.uuid4())\n",
        "        edge['~from'] = source\n",
        "        edge['~to'] = target\n",
        "        edge['~label'] = \"RETWEETED\"\n",
        "        edge['weight:Int'] = int(attributes['weight'])\n",
        "        edge['tweet_ids'] = \";\".join(attributes['tweet_ids'])\n",
        "        edges.append(edge)\n",
        "    return edges\n",
        "\n",
        "def create_follower_edges(sources, target):\n",
        "    edges = []\n",
        "    for source in sources:\n",
        "        edge = {}\n",
        "        edge['~id'] = str(uuid.uuid4())\n",
        "        edge['~from'] = source\n",
        "        edge['~to'] = target\n",
        "        edge['~label'] = \"FOLLOWS\"\n",
        "        edges.append(edge)\n",
        "    return edges\n",
        "\n",
        "# file paths\n",
        "user_vertices_file_path = os.path.join(base_path, city_name, f\"{city_name}_user_vertices.csv\")\n",
        "city_edges_file_path = os.path.join(base_path, city_name, f\"{city_name}_city_edges.csv\")\n",
        "retweeter_edges_file_path = os.path.join(base_path, city_name, f\"{city_name}_retweeter_edges.csv\")\n",
        "follower_edges_file_path = os.path.join(base_path, city_name, f\"{city_name}_follower_edges.csv\")\n",
        "\n",
        "# fieldnames\n",
        "user_vertices_fieldnames = [\"~id\", \"~label\", \"username\", \"city\", \"profile_location\", \"target_location\",\n",
        "                            \"followers_count:Int\", \"following_count:Int\", \"tweets_count:Int\", \"category\", \"treatment_arm\",\n",
        "                            \"verified\", \"created_at\", \"last_tweeted_at\", \"retweeter_status\", \n",
        "                            \"retweeter_last_processed\", \"follower_status\", \"follower_last_processed\", \n",
        "                            \"extracted_at\", \"last_updated\"]\n",
        "\n",
        "# creating master lists to ensure no repetitions occur\n",
        "root_users = []\n",
        "all_users = []\n",
        "\n",
        "## MAIN ##\n",
        "for root_user in raw_network:\n",
        "    print(f\"Processing root user: {root_user['user_id']}\")\n",
        "\n",
        "    # ensure user id exists\n",
        "    if not root_user.get('user_id'):\n",
        "        print(\"!! Invalid user_id. Skipping... !!\")\n",
        "        continue\n",
        "    # ensure root user hasn't already been processed\n",
        "    if root_user['user_id'] in root_users:\n",
        "        print(\"!! Root user has already been processed. Skipping... !!\")\n",
        "        continue\n",
        "    # ensure root user meets basic criteria\n",
        "    if (not root_user.get('city')) or (root_user['city'] != root_user['target_location']):\n",
        "        print(\"!! Root user does not meet location criteria. Skipping... !!\")\n",
        "        continue\n",
        "\n",
        "    # create and write user vertex\n",
        "    if root_user['user_id'] not in all_users:\n",
        "        user_vertex = create_user_vertex(root_user)\n",
        "        write_dict_to_csv(user_vertices_file_path, user_vertex, user_vertices_fieldnames)\n",
        "        all_users.append(root_user['user_id'])\n",
        "\n",
        "    # create and write city edges \n",
        "    city_edge = create_city_edge(root_user['user_id'], root_user['city'])\n",
        "    write_dict_to_csv(city_edges_file_path, city_edge)\n",
        "\n",
        "    # create and write retweeter edges + corresponding user vertices\n",
        "    if root_user.get('tweets'):\n",
        "        retweet_sources = {}\n",
        "        for tweet in root_user['tweets']:\n",
        "            if tweet.get('retweeters'):\n",
        "                for retweeter in tweet['retweeters']:\n",
        "                    if retweeter['user_id'] not in all_users:\n",
        "                        user_vertex = create_user_vertex(retweeter)\n",
        "                        write_dict_to_csv(user_vertices_file_path, user_vertex, user_vertices_fieldnames)\n",
        "                        all_users.append(retweeter['user_id'])\n",
        "                    if retweeter['user_id'] not in retweet_sources:\n",
        "                        retweet_sources[retweeter['user_id']] = {'weight': 0, 'tweet_ids': []}\n",
        "                    retweet_sources[retweeter['user_id']]['weight'] += 1\n",
        "                    retweet_sources[retweeter['user_id']]['tweet_ids'].append(tweet['tweet_id'])\n",
        "        if retweet_sources:\n",
        "            retweeter_edges = create_retweeter_edges(retweet_sources, root_user['user_id'])\n",
        "            for edge in retweeter_edges:\n",
        "                write_dict_to_csv(retweeter_edges_file_path, edge)\n",
        "    \n",
        "    # create and write follower edges + corresponding user vertices\n",
        "    if root_user.get('followers'):\n",
        "        follower_sources = []\n",
        "        for follower in root_user['followers']:\n",
        "            if follower['user_id'] not in all_users:\n",
        "                user_vertex = create_user_vertex(follower)\n",
        "                write_dict_to_csv(user_vertices_file_path, user_vertex, user_vertices_fieldnames)\n",
        "                all_users.append(follower['user_id'])\n",
        "            if follower['user_id'] not in follower_sources:\n",
        "                follower_sources.append(follower['user_id'])\n",
        "        if follower_sources:\n",
        "            follower_edges = create_follower_edges(follower_sources, root_user['user_id'])\n",
        "            for edge in follower_edges:\n",
        "                write_dict_to_csv(follower_edges_file_path, edge)\n",
        "\n",
        "    # append root user to master list\n",
        "    root_users.append(root_user['user_id'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
